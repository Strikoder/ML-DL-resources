{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1781e+00,  1.4841e-01, -7.0080e-01,  ...,  1.1856e+00,\n",
      "          -3.4810e-01,  2.2296e-01],\n",
      "         [ 6.8155e-01,  8.4364e-01, -1.5005e+00,  ..., -8.6762e-02,\n",
      "          -1.8138e+00,  6.2113e-01],\n",
      "         [ 4.5144e-01,  1.1330e+00, -1.0829e+00,  ...,  8.0591e-01,\n",
      "          -5.7017e-01,  6.7763e-02],\n",
      "         ...,\n",
      "         [ 7.5145e-01, -7.6074e-01, -1.0524e+00,  ..., -4.8734e-01,\n",
      "          -1.5585e-01, -1.3068e+00],\n",
      "         [ 7.9490e-01, -1.0910e+00, -1.2889e-01,  ..., -1.1822e-01,\n",
      "          -2.6666e+00, -1.2966e+00],\n",
      "         [ 1.2134e+00, -8.0573e-01, -1.6540e+00,  ...,  5.2009e-01,\n",
      "          -1.4772e+00, -5.4820e-01]],\n",
      "\n",
      "        [[ 4.7008e-02, -2.9697e-01, -4.8584e-01,  ...,  5.1817e-01,\n",
      "          -1.8642e+00,  1.8510e+00],\n",
      "         [-6.3696e-01, -1.3792e+00, -7.9070e-01,  ...,  1.2614e+00,\n",
      "          -1.8337e+00,  3.6326e-01],\n",
      "         [ 1.3495e+00, -1.3591e-01, -1.1504e+00,  ..., -2.0536e-02,\n",
      "          -9.1363e-01,  2.8693e-01],\n",
      "         ...,\n",
      "         [ 9.1070e-01, -8.8692e-01, -2.8237e-01,  ...,  3.0242e-01,\n",
      "          -1.0723e+00, -2.5570e-01],\n",
      "         [-6.4163e-01, -9.0548e-01, -1.1907e+00,  ...,  4.3189e-01,\n",
      "          -9.4153e-01,  5.1328e-01],\n",
      "         [ 6.5317e-01, -2.4059e-01, -5.6036e-01,  ...,  1.1414e-01,\n",
      "          -7.1462e-01, -2.4634e-01]],\n",
      "\n",
      "        [[ 4.1705e-01,  4.0230e-01, -9.7959e-01,  ...,  1.4306e+00,\n",
      "          -1.5360e+00, -4.0797e-01],\n",
      "         [ 1.1387e+00,  3.3186e-02,  8.2199e-01,  ...,  1.0543e+00,\n",
      "          -1.2384e+00,  6.4661e-01],\n",
      "         [ 1.5813e+00,  5.0122e-01,  3.1922e-01,  ...,  1.7331e-01,\n",
      "          -1.9939e+00,  1.2978e+00],\n",
      "         ...,\n",
      "         [-8.7451e-01, -8.1519e-01, -2.1005e-01,  ...,  3.3528e-01,\n",
      "          -1.9909e+00, -1.9380e-01],\n",
      "         [ 1.0196e+00, -8.9769e-01,  2.6362e-01,  ...,  1.2550e+00,\n",
      "          -2.5200e-01, -1.2219e+00],\n",
      "         [-3.2712e-01, -4.3275e-01, -1.0163e+00,  ...,  2.5834e-01,\n",
      "          -4.9064e-01,  2.4225e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5353e+00, -2.0193e+00, -2.2203e-01,  ...,  7.1518e-01,\n",
      "          -1.5497e+00, -6.0285e-01],\n",
      "         [-4.2485e-01, -1.2109e+00, -9.9193e-01,  ...,  8.5517e-01,\n",
      "          -1.9036e+00, -6.8660e-01],\n",
      "         [ 7.5845e-01,  1.0295e-01, -1.6120e-01,  ...,  5.0364e-01,\n",
      "           5.9173e-02, -1.5175e+00],\n",
      "         ...,\n",
      "         [-5.0963e-01, -8.8963e-01,  6.4482e-04,  ..., -9.0446e-01,\n",
      "           6.5878e-01, -1.1819e+00],\n",
      "         [ 5.5239e-01, -9.5981e-01, -1.2062e+00,  ..., -1.5940e-01,\n",
      "          -1.5211e+00,  2.1809e-01],\n",
      "         [ 1.4114e+00, -6.6315e-01, -8.6810e-02,  ...,  1.2318e+00,\n",
      "          -1.5998e+00,  5.7585e-01]],\n",
      "\n",
      "        [[ 2.5434e-01, -2.0798e-01, -1.6335e+00,  ...,  2.4927e-01,\n",
      "          -1.3896e+00,  7.5064e-01],\n",
      "         [ 2.3357e+00, -3.6487e-02, -1.2170e+00,  ..., -4.0150e-02,\n",
      "          -1.1620e+00,  1.0202e+00],\n",
      "         [ 1.7597e+00,  6.1620e-01, -4.6559e-01,  ...,  2.3601e-01,\n",
      "           1.9378e-01, -4.0787e-01],\n",
      "         ...,\n",
      "         [ 1.4982e+00, -9.0434e-01, -1.3967e+00,  ..., -2.4823e-01,\n",
      "          -6.2876e-01, -7.2952e-01],\n",
      "         [ 3.5052e-01, -2.7382e-01, -1.0218e+00,  ...,  7.5130e-01,\n",
      "          -6.7240e-01,  1.0622e-01],\n",
      "         [ 5.0594e-01,  4.8477e-01, -1.4633e-01,  ..., -6.4426e-02,\n",
      "          -1.3406e+00,  7.3062e-01]],\n",
      "\n",
      "        [[-2.3504e-01, -4.9587e-01, -5.4814e-01,  ...,  1.8303e+00,\n",
      "          -7.6898e-01, -1.4482e+00],\n",
      "         [ 7.4020e-01, -1.6765e+00, -8.7938e-01,  ...,  1.1113e+00,\n",
      "          -3.6331e-01,  2.2133e-01],\n",
      "         [ 2.0776e+00, -1.1458e+00, -1.4752e-01,  ...,  1.2290e+00,\n",
      "          -7.4405e-01, -2.8995e-01],\n",
      "         ...,\n",
      "         [ 1.2887e+00, -2.8192e-01, -1.2423e+00,  ..., -1.1576e-01,\n",
      "          -1.4391e+00,  7.7228e-01],\n",
      "         [ 1.0238e+00, -7.4550e-02, -2.0777e-01,  ...,  7.8355e-01,\n",
      "          -4.2397e-01,  4.7157e-01],\n",
      "         [ 7.0324e-01, -9.2548e-01, -2.9101e-02,  ..., -2.6200e-02,\n",
      "          -8.9091e-01, -1.0337e+00]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Scaled Dot-Product Attention\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "    def forward(self, Q, K, V):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_k ** 0.5)\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attn, V)\n",
    "        return output\n",
    "\n",
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        batch_size = Q.size(0)\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_values = self.attention(Q, K, V)\n",
    "\n",
    "        # Concatenate and pass through final linear layer\n",
    "        concat = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        output = self.W_o(concat)\n",
    "        return output\n",
    "\n",
    "# Position-wise Feed-Forward Network\n",
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = PositionwiseFeedforward(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(x + self.attention(x, x, x))\n",
    "        x = self.norm2(x + self.ff(x))\n",
    "        return x\n",
    "\n",
    "# Transformer Model\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerBlock(d_model, num_heads, d_ff) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Example Usage\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "\n",
    "model = Transformer(num_layers, d_model, num_heads, d_ff)\n",
    "\n",
    "# Dummy input (batch size, sequence length, d_model)\n",
    "x = torch.rand(64, 10, d_model)\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
